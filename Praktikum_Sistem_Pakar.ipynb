{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAAb_e1P4Lde",
        "outputId": "b1908cbb-cfa6-4321-f811-00a8e55c16ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting experta\n",
            "  Downloading experta-1.9.4-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting frozendict==1.2 (from experta)\n",
            "  Downloading frozendict-1.2.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema==0.6.7 (from experta)\n",
            "  Downloading schema-0.6.7-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Downloading experta-1.9.4-py3-none-any.whl (35 kB)\n",
            "Downloading schema-0.6.7-py2.py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-py3-none-any.whl size=3149 sha256=b38d48d14abbb7ff90b7c070910f713255c943d7d47fe6f9e4f2664f75ad77df\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ac/f8/cb8120244e710bdb479c86198b03c7b08c3c2d3d2bf448fd6e\n",
            "Successfully built frozendict\n",
            "Installing collected packages: schema, frozendict, experta\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 2.4.6\n",
            "    Uninstalling frozendict-2.4.6:\n",
            "      Successfully uninstalled frozendict-2.4.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.55 requires frozendict>=2.3.4, but you have frozendict 1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed experta-1.9.4 frozendict-1.2 schema-0.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install experta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade frozendict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6oeL7w05WPr",
        "outputId": "2dad5820-e031-4cf4-ee17-4f9296a1cf1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
            "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
            "Installing collected packages: frozendict\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 1.2\n",
            "    Uninstalling frozendict-1.2:\n",
            "      Successfully uninstalled frozendict-1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "experta 1.9.4 requires frozendict==1.2, but you have frozendict 2.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed frozendict-2.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class Diagnosis(KnowledgeEngine):\n",
        "\n",
        "  @Rule(Fact(cough=True) & Fact(fever=True) & Fact(fatigue=True))\n",
        "  def flu(self):\n",
        "    print(\"Diagnosis: Yout may have the flu.\")\n",
        "\n",
        "  @Rule(Fact(cough=True) & Fact(fever=True) & Fact(breathing_difficulty=True))\n",
        "  def pneumonia(self):\n",
        "    print(\"Diagnosis: You may have Pneumonia.\")\n",
        "\n",
        "  @Rule(Fact(sneezing=True) & Fact(runny_nose=True) & Fact(cough=False))\n",
        "  def cold(self):\n",
        "    print(\"Diagnosis: You may have a Common Cold.\")\n",
        "\n",
        "  @Rule(Fact(sore_throat=True) & Fact(fever=True))\n",
        "  def throat_infection(self):\n",
        "    print(\"Diagnosis: You may have a Throat Infection.\")\n",
        "\n",
        "  @Rule(Fact(cough=False) & Fact(fever=False) & Fact(fatigue=False))\n",
        "  def healthy(self):\n",
        "    print(\"Diagnosis: You may seem to be Healthy.\")\n",
        "\n",
        "def get_input():\n",
        "  \"\"\"Helper function to get user input as boolean (yes/no).\"\"\"\n",
        "  def ask_question(question):\n",
        "    return input(question + \" (yes/no): \"). strip().lower() == \"yes\"\n",
        "\n",
        "  return {\n",
        "      \"cough\": ask_question(\"Do you have a cough?\"),\n",
        "      \"fever\": ask_question(\"Do you have a fever?\"),\n",
        "      \"fatigue\": ask_question(\"Do you feel fatigued?\"),\n",
        "      \"breathing_difficulty\": ask_question(\"Do you have breathing difficulties?\"),\n",
        "      \"sneezing\": ask_question(\"Are you sneezing?\"),\n",
        "      \"runny_nose\": ask_question(\"Do you have a runny nose?\"),\n",
        "      \"sore_throat\": ask_question(\"Do you have a sore throat?\")\n",
        "  }\n",
        "\n",
        "# Running the Expert System\n",
        "if __name__ == \"__main__\":\n",
        "  symptoms = get_input()\n",
        "  engine = Diagnosis()\n",
        "  engine.reset() # Reset the knowledge engine\n",
        "\n",
        "  for symptom, present in symptoms.items():\n",
        "    engine.declare(Fact(**{symptom: present})) #Declare facts\n",
        "\n",
        "  engine.run() # Run the inference engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju7aZMxM5m-H",
        "outputId": "136b7c4f-6465-41cc-8ceb-fb2e93a02370"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do you have a cough? (yes/no): yes\n",
            "Do you have a fever? (yes/no): yes\n",
            "Do you feel fatigued? (yes/no): yes\n",
            "Do you have breathing difficulties? (yes/no): no\n",
            "Are you sneezing? (yes/no): no\n",
            "Do you have a runny nose? (yes/no): no\n",
            "Do you have a sore throat? (yes/no): no\n",
            "Diagnosis: Yout may have the flu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward Chaining"
      ],
      "metadata": {
        "id": "saX3oXmdDNUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class SistemPakarMedis(KnowledgeEngine):\n",
        "  @Rule(Fact(demam=True) & Fact(batuk=True))\n",
        "  def flu(self):\n",
        "    print(\"Diagnosis: Flu.\")\n",
        "\n",
        "  @Rule(Fact(sakit_tenggorokan=True) & Fact(demam=True))\n",
        "  def throat_infection(self):\n",
        "    print(\"Diagnosis: Radang Tenggorokan.\")\n",
        "\n",
        "# Running the Expert System\n",
        "engine = SistemPakarMedis()\n",
        "engine.reset()\n",
        "engine.declare(Fact(demam=True))\n",
        "engine.declare(Fact(sakit_tenggorokan=True)) # Input symptoms\n",
        "engine.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvYnam8eDGCf",
        "outputId": "f4b07731-8a59-4e7e-fa47-af2a2b6a6c0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnosis: Radang Tenggorokan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diagnosis: Radang Tenggorokan"
      ],
      "metadata": {
        "id": "6zAQI9eZH5-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(facts, rules):\n",
        "  inferred = set(facts)\n",
        "  changed = True\n",
        "\n",
        "  while changed:\n",
        "    changed = False\n",
        "    for rule in rules:\n",
        "      if rule[\"if\"]. issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "        inferred. add(rule[\"then\"])\n",
        "        changed = True\n",
        "  return inferred\n",
        "\n",
        "facts = {\"has_feathers\", \"has_beak\", \"lays_eggs\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_feathers\", \"can_fly\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"lays_eggs\", \"is_bird\"}, \"then\": \"is_chicken\"},\n",
        "    {\"if\": {\"cannot_fly\", \"is_bird\"}, \"then\": \"is_penguin\"},\n",
        "    {\"if\": {\"carnivore\", \"is_bird\"}, \"then\": \"is_eagle\"}\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"Inferred facts: \", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYBpYNbIH9cG",
        "outputId": "9c951e93-f6bd-470a-e275-f43e004cb02b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred facts:  {'is_bird', 'can_fly', 'is_chicken', 'lays_eggs', 'has_feathers'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chaining(goal, facts, rules):\n",
        "  if goal in facts:\n",
        "    return True\n",
        "  for rule in rules:\n",
        "    if rule[\"then\"] == goal:\n",
        "      if all(backward_chaining(cond, facts, rules) for cond in rule[\"if\"]):\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "facts = {\"likes_computers\", \"solves_problems\", \"likes_to_design\"}\n",
        "rules = [\n",
        "    {\"if\": {\"likes_computers\", \"solves_problems\"}, \"then\": \"should_be_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"likes_programming\"}, \"then\": \"software_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"likes_to_design\"}, \"then\": \"UI/UX_engineer\"}\n",
        "]\n",
        "\n",
        "goal = \"UI/UX_engineer\"\n",
        "result = backward_chaining(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? -> \", result)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHILl6IzNXwZ",
        "outputId": "102b8021-9a07-4b8e-9573-3fcdcb946dda"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'UI/UX_engineer' provable? ->  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas Praktikum"
      ],
      "metadata": {
        "id": "9VdijPiPQ5Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOAL 1 forward_chaining dan print hasil inferensi nya"
      ],
      "metadata": {
        "id": "gCvVgdxWRvS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(facts, rules):\n",
        "  inferred = set(facts)\n",
        "  changed = True\n",
        "\n",
        "  while changed:\n",
        "    changed = False\n",
        "    for rule in rules:\n",
        "      if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "        inferred.add(rule[\"then\"])\n",
        "        changed = True\n",
        "  return inferred\n",
        "\n",
        "facts = {\"has_wheels\", \"has_engine\", \"has_four_wheels\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_wheels\", \"has_engine\"}, \"then\": \"is_vehicle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_two_wheels\"}, \"then\": \"is_motorcyle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_four_wheels\"}, \"then\": \"is_car\"}\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"Inferred facts: \", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4DKFe81Qz8s",
        "outputId": "f31db503-ba29-4d6b-98cb-2aca78a63365"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred facts:  {'has_four_wheels', 'has_engine', 'is_car', 'is_vehicle', 'has_wheels'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SOAL 2 Backward Chaining\n",
        "buatlah 3 variable goal, facts, rules\n",
        "Goal: is_penguin Rules:"
      ],
      "metadata": {
        "id": "ZE1pTn3zUIGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chaining(goal, facts, rules):\n",
        "  if goal in facts:\n",
        "    return True\n",
        "  for rule in rules:\n",
        "    if rule[\"then\"] == goal:\n",
        "      if all(backward_chaining(cond, facts, rules) for cond in rule[\"if\"]):\n",
        "        return True\n",
        "  return False\n",
        "\n",
        "facts = {\"has_feathers\", \"has_small_wings\"}\n",
        "rules = [\n",
        "    {\"if\": {\"is_bird\", \"cannot_fly\"}, \"then\": \"is_penguin\"},\n",
        "    {\"if\": {\"has_feathers\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"has_small_wings\"}, \"then\": \"cannot_fly\"}\n",
        "]\n",
        "\n",
        "goal = \"is_penguin\"\n",
        "result = backward_chaining(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? -> \", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntcwi_ScThAz",
        "outputId": "7dc4b3ea-ceee-4d66-e026-ae28d333bc9a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'is_penguin' provable? ->  True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pL3ooxWPQ54L"
      }
    }
  ]
}